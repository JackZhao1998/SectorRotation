{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34d2cba-f1b3-4b3a-822a-3b1f8cc40a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "startDate = datetime(2015,3,1)\n",
    "endDate = datetime(2021,12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3cebb2d5-74da-4b22-a191-7a242a99fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            material    energy  industrial  consumer_discretionary  \\\n",
      "Dates                                                                \n",
      "2012-12-31       NaN       NaN         NaN                     NaN   \n",
      "2013-03-29       NaN       NaN         NaN                     NaN   \n",
      "2013-06-28       NaN       NaN         NaN                     NaN   \n",
      "2013-09-30       NaN       NaN         NaN                     NaN   \n",
      "2013-12-31       NaN       NaN         NaN                     NaN   \n",
      "2014-03-31       NaN       NaN         NaN                     NaN   \n",
      "2014-06-30       NaN       NaN         NaN                     NaN   \n",
      "2014-09-30       NaN       NaN         NaN                     NaN   \n",
      "2014-12-31       NaN       NaN         NaN                     NaN   \n",
      "2015-03-31  0.683231  2.661100    0.331662                0.587719   \n",
      "2015-06-30  1.240638  2.707288   -0.445209                0.332837   \n",
      "2015-09-30  1.539492  1.517428   -2.244630               -0.595290   \n",
      "2015-12-31  2.344841  1.517428    1.012951               -0.102525   \n",
      "2016-03-31  2.347442  1.517428    1.686750               -0.570512   \n",
      "2016-06-30  1.624638  1.517428    1.619907               -1.172130   \n",
      "2016-09-30  0.940583  1.517428    1.510702                1.118214   \n",
      "2016-12-30  0.038318  1.517428    1.703509                0.224987   \n",
      "2017-03-31 -0.434272  1.517428    1.367626                1.610469   \n",
      "2017-06-30 -0.556284  1.517428    1.259942                1.734071   \n",
      "2017-09-29 -0.567026  1.517428    1.272392                1.428384   \n",
      "2017-12-29 -0.381173  1.517428    1.847370                1.930548   \n",
      "2018-03-30 -0.799136  1.517428    1.454701                1.755142   \n",
      "2018-06-29 -1.128129  1.517428    0.533042                1.953154   \n",
      "2018-09-28 -1.211819  1.517428    2.170259                2.289769   \n",
      "2018-12-31 -2.048696  1.517428   -0.468533                0.647810   \n",
      "2019-03-29 -0.872100  1.517428    0.696943                1.653028   \n",
      "2019-06-28  1.300174  1.517428    1.096970                1.569608   \n",
      "2019-09-30  1.719936 -0.533161   -0.519774                0.909345   \n",
      "2019-12-31  1.723097  1.012747   -0.069302                0.863527   \n",
      "2020-03-31  0.419251  0.113273   -1.583076               -0.078614   \n",
      "2020-06-30  1.749367  0.113273    1.991539                2.663895   \n",
      "2020-09-30  1.976275  0.113273    2.506215                2.132586   \n",
      "2020-12-31  1.081351  0.113273    2.424686                2.096655   \n",
      "2021-03-31  0.388095  0.113273    1.548686                1.069051   \n",
      "2021-06-30 -0.951003  0.113273    0.206140                0.034404   \n",
      "2021-09-30 -1.652610  0.113273   -0.412935               -0.231014   \n",
      "\n",
      "            consumer_staple  health_care        IT  financial  real_estate  \\\n",
      "Dates                                                                        \n",
      "2012-12-31              NaN          NaN       NaN        NaN          NaN   \n",
      "2013-03-29              NaN          NaN       NaN        NaN          NaN   \n",
      "2013-06-28              NaN          NaN       NaN        NaN          NaN   \n",
      "2013-09-30              NaN          NaN       NaN        NaN          NaN   \n",
      "2013-12-31              NaN          NaN       NaN        NaN          NaN   \n",
      "2014-03-31              NaN          NaN       NaN        NaN          NaN   \n",
      "2014-06-30              NaN          NaN       NaN        NaN          NaN   \n",
      "2014-09-30              NaN          NaN       NaN        NaN          NaN   \n",
      "2014-12-31              NaN          NaN       NaN        NaN          NaN   \n",
      "2015-03-31         1.694669     1.786486  1.052019  -0.724165          NaN   \n",
      "2015-06-30         1.452893     1.578203  1.308253  -0.482343          NaN   \n",
      "2015-09-30         0.697501     0.157039  0.356015  -2.057378          NaN   \n",
      "2015-12-31         1.245575     0.487318  1.499782  -1.642982          NaN   \n",
      "2016-03-31         1.097665    -0.520824  2.074371  -0.957933          NaN   \n",
      "2016-06-30         1.157931    -0.466140  1.245508  -0.608630          NaN   \n",
      "2016-09-30         0.863004    -0.964815  2.184458  -1.879295          NaN   \n",
      "2016-12-30        -0.658160    -1.336802  1.079203  -0.592457          NaN   \n",
      "2017-03-31         0.743692    -0.904176  1.768042  -0.556051          NaN   \n",
      "2017-06-30         0.974014    -0.185640  1.304965   0.146098          NaN   \n",
      "2017-09-29         0.083830     1.021521  1.324611   1.647388          NaN   \n",
      "2017-12-29         1.331902     1.741374  1.340880   1.886437          NaN   \n",
      "2018-03-30        -0.557883     1.243091  1.343600   1.281359          NaN   \n",
      "2018-06-29        -0.768571     1.724646  1.140163  -0.544491          NaN   \n",
      "2018-09-28         0.747927     1.719772  0.935259  -1.102821          NaN   \n",
      "2018-12-31         1.999145     1.320111 -1.925115  -1.541371    -2.321809   \n",
      "2019-03-29         2.336399     1.322987  0.651205  -1.240163     1.671513   \n",
      "2019-06-28         2.406365     0.305592  1.217549  -0.882388     1.914037   \n",
      "2019-09-30         1.904765    -0.325368  1.743555  -0.820257     1.812814   \n",
      "2019-12-31         1.097475     0.530521  2.103409  -1.186965     1.212621   \n",
      "2020-03-31         0.075582    -1.903253  0.716648  -1.249972    -0.706825   \n",
      "2020-06-30         0.124736     0.201956  2.167031   0.349556     1.377124   \n",
      "2020-09-30         0.214752     0.900932  1.873131   0.870829     1.775223   \n",
      "2020-12-31         0.147978     2.410174  1.664581   1.988274     1.813562   \n",
      "2021-03-31        -0.267658     1.586616  1.008243  -1.243391     1.580665   \n",
      "2021-06-30        -0.880219     1.183167  0.856953  -1.752396     1.225433   \n",
      "2021-09-30        -1.322247     0.105406  0.362140  -1.470800     0.565254   \n",
      "\n",
      "             utility   telecom  \n",
      "Dates                           \n",
      "2012-12-31       NaN       NaN  \n",
      "2013-03-29       NaN       NaN  \n",
      "2013-06-28       NaN       NaN  \n",
      "2013-09-30       NaN       NaN  \n",
      "2013-12-31       NaN       NaN  \n",
      "2014-03-31       NaN       NaN  \n",
      "2014-06-30       NaN       NaN  \n",
      "2014-09-30       NaN       NaN  \n",
      "2014-12-31       NaN       NaN  \n",
      "2015-03-31 -1.262138  0.624688  \n",
      "2015-06-30 -2.130737  0.653158  \n",
      "2015-09-30 -0.954028  0.815035  \n",
      "2015-12-31  2.059303 -0.547682  \n",
      "2016-03-31  2.453591 -0.277613  \n",
      "2016-06-30  2.203709 -0.210836  \n",
      "2016-09-30  1.411926 -0.416494  \n",
      "2016-12-30  1.809557 -0.146352  \n",
      "2017-03-31  1.339735 -0.382478  \n",
      "2017-06-30  1.225462 -0.751408  \n",
      "2017-09-29  0.887626 -0.492266  \n",
      "2017-12-29 -0.267864  0.639661  \n",
      "2018-03-30 -1.010399  0.918476  \n",
      "2018-06-29 -0.304978  2.145525  \n",
      "2018-09-28 -0.119636  2.243340  \n",
      "2018-12-31  2.202171  0.997208  \n",
      "2019-03-29  0.340355  1.921365  \n",
      "2019-06-28  0.115494  1.345593  \n",
      "2019-09-30  0.208302  1.000476  \n",
      "2019-12-31 -0.107590  0.985409  \n",
      "2020-03-31 -0.569819 -0.434005  \n",
      "2020-06-30 -0.459156  0.996645  \n",
      "2020-09-30  0.161415  1.459476  \n",
      "2020-12-31  0.716220  2.254974  \n",
      "2021-03-31  0.948624  1.535460  \n",
      "2021-06-30  1.682464  1.168843  \n",
      "2021-09-30  1.609569  0.331361  \n"
     ]
    }
   ],
   "source": [
    "#clean data functions\n",
    "sector_dict={\n",
    "            'S&P 500 Materials Sector GICS Level 1 Index': 'material',\n",
    "            'S&P 500 Energy Sector GICS Level 1 Index':\t'energy',\n",
    "            'S&P 500 Industrials Sector GICS Level 1 Index':'industrial',\n",
    "            'S&P 500 Consumer Discretionary Sector GICS Level 1 Index':'consumer_discretionary',\n",
    "            'S&P 500 Consumer Staples Sector GICS Level 1 Index':'consumer_staple',\n",
    "            'S&P 500 Health Care Sector GICS Level 1 Index':'health_care',\n",
    "            'S&P 500 Information Technology Sector GICS Level 1 Index':'IT',\n",
    "            'S&P 500 Financials Sector GICS Level 1 Index': 'financial',\n",
    "            'S&P 500 Real Estate Sector GICS Level 1 Index': 'real_estate',\n",
    "            'S&P 500 Utilities Sector GICS Level 1 Index': 'utility',\n",
    "            'S&P 500 Communication Services Sector GICS Level 1 Index':'telecom'\n",
    "            }\n",
    "\n",
    "sector_list = ['energy','material','industrial','consumer_discretionary','consumer_staple','health_care','financial','IT','telecom','utility','real_estate']\n",
    "factor_list=['PE','PB','EV2Sales','EV2EBIT','EV2EBITDA','DIV_Y','OM','PM','ROA','ROE']\n",
    "\n",
    "def clean_fdmt_data(df):\n",
    "    df=df.drop(columns=['Unnamed: 0'])\n",
    "    df=df.rename(columns={'3 Months Ending':'Dates'})\n",
    "    df=df.set_index('Dates')\n",
    "    df=df.rename(columns=sector_dict)\n",
    "    df=df.truncate(after=endDate)\n",
    "    return(df)\n",
    "\n",
    "def factor_neutralize(df):\n",
    "    df_cal = df\n",
    "    df_mean = df_cal.rolling(10).mean()\n",
    "    df_std = df_cal.rolling(10).std()\n",
    "    df_neutral = df_cal.sub(df_mean).div(df_std)\n",
    "    return(df_neutral)\n",
    "\n",
    "#import&clean Data\n",
    "#PE ratio\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/PE Ratio.xlsx',parse_dates=['3 Months Ending'])\n",
    "PE_df=clean_fdmt_data(df)\n",
    "PE_neutral=factor_neutralize(PE_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#PB ratio\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/PB Ratio.xlsx',parse_dates=['3 Months Ending'])\n",
    "PB_df=clean_fdmt_data(df)\n",
    "PB_neutral=factor_neutralize(PB_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "\n",
    "#EV2Sales\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/EV2Sales.xlsx',parse_dates=['3 Months Ending'])\n",
    "EV2Sales_df=clean_fdmt_data(df)\n",
    "EV2Sales_neutral=factor_neutralize(EV2Sales_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#EV2EBIT\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/EV2EBIT.xlsx',parse_dates=['3 Months Ending'])\n",
    "EV2EBIT_df=clean_fdmt_data(df)\n",
    "EV2EBIT_neutral=factor_neutralize(EV2EBIT_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#EV2EBITDA\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/EV2EBITDA.xlsx',parse_dates=['3 Months Ending'])\n",
    "EV2EBITDA_df=clean_fdmt_data(df)\n",
    "EV2EBITDA_neutral=factor_neutralize(EV2EBITDA_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#Dividend Yield\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/Dividend Yield.xlsx',parse_dates=['3 Months Ending'])\n",
    "DIV_Y_df=clean_fdmt_data(df)\n",
    "DIV_Y_neutral=factor_neutralize(DIV_Y_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#Gross Margin\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/Gross Margin.xlsx',parse_dates=['3 Months Ending'])\n",
    "GM_df=clean_fdmt_data(df)\n",
    "GM_neutral=factor_neutralize(GM_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#Operating Margin\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/operatingmargin.xlsx',parse_dates=['3 Months Ending'])\n",
    "OM_df=clean_fdmt_data(df)\n",
    "OM_neutral=factor_neutralize(OM_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#profit Margin\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/profit margin.xlsx',parse_dates=['3 Months Ending'])\n",
    "PM_df=clean_fdmt_data(df)\n",
    "PM_neutral=factor_neutralize(PM_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#return on asset\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/return on asset.xlsx',parse_dates=['3 Months Ending'])\n",
    "ROA_df=clean_fdmt_data(df)\n",
    "ROA_neutral=factor_neutralize(ROA_df).truncate(before=startDate,after=endDate).fillna(method='ffill')\n",
    "\n",
    "#return on equity\n",
    "df=pd.read_excel('/Users/JackRitian/Desktop/sector rotation/data/Fundamentals/return on equity.xlsx',parse_dates=['3 Months Ending'])\n",
    "ROE_df=clean_fdmt_data(df)\n",
    "ROE_neutral=factor_neutralize(ROE_df).truncate(before=startDate,after=endDate).fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "13f9f842-da14-4156-b953-329074d6123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factor_exposure(sector):\n",
    "    rename_dict={sector:'PE'}\n",
    "    PE_exposures=PE_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'PB'}\n",
    "    PB_exposures=PB_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'EV2Sales'}\n",
    "    EV2Sales_exposures=EV2Sales_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'EV2EBIT'}\n",
    "    EV2EBIT_exposures=EV2EBIT_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'EV2EBITDA'}\n",
    "    EV2EBITDA_exposures=EV2EBITDA_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'DIV_Y'}\n",
    "    DIV_Y_exposures=DIV_Y_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'GM'}\n",
    "    GM_exposures=GM_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'OM'}\n",
    "    OM_exposures=OM_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'PM'}\n",
    "    PM_exposures=PM_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'ROA'}\n",
    "    ROA_exposures=ROA_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    rename_dict={sector:'ROE'}\n",
    "    ROE_exposures=ROE_neutral[sector].to_frame().rename(columns=rename_dict)\n",
    "\n",
    "    factor_exposure=PE_exposures.join(PB_exposures).join(EV2Sales_exposures).join(EV2EBIT_exposures).join(EV2EBITDA_exposures).join(DIV_Y_exposures).join(GM_exposures).join(OM_exposures).join(PM_exposures).join(ROA_exposures).join(ROE_exposures)\n",
    "\n",
    "    return(factor_exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b059765f-1584-4f70-b4f3-591afeb9ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "---------------------------------------------------- Return to Factor Exposure------------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "sector_index=pd.read_csv('/Users/JackRitian/Desktop/sector rotation/data/index data/sector_index.csv',parse_dates=['Date'])\n",
    "sector_index=sector_index.set_index('Date')\n",
    "quarterly_index_rtn=sector_index.resample(\"Q\").last().pct_change().shift(-1).dropna()\n",
    "quarterly_index_rtn=quarterly_index_rtn.truncate(before='2015-03-01',after='2021-12-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a75f9f4a-6927-45b3-aa2c-d0510d38899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0032748907853532155\n",
      "0.010530904384714879\n",
      "0.020319913366075894\n",
      "0.028311336652075546\n",
      "0.010475144941742523\n",
      "0.016929943164332592\n",
      "nan\n",
      "0.04343745002906239\n",
      "0.005163512340922209\n",
      "0.018325551539981395\n",
      "0.16635475098870423\n"
     ]
    }
   ],
   "source": [
    "def get_sector_exposure(sector,factor_list):    \n",
    "    factor_exposure=get_factor_exposure(sector)\n",
    "    factor_exposure=factor_exposure[factor_list].truncate(before='2015-03-01',after='2021-12-1')\n",
    "    df = factor_exposure\n",
    "    return df\n",
    "\n",
    "startDate = datetime(2012,12,1)\n",
    "endDate = datetime(2021,12,1)\n",
    "date_list = quarterly_index_rtn.index.to_list()\n",
    "\n",
    "def mean_divide_sig(rtn_df,mean):\n",
    "    sig = []\n",
    "    for rtn in rtn_df['Return']:\n",
    "        if rtn - mean >0:\n",
    "            sig.append(1)\n",
    "        else:\n",
    "            sig.append(0)\n",
    "    rtn_df['sig']=sig\n",
    "    return rtn_df\n",
    "    \n",
    "\n",
    "def split_dataset(df,factor_list):\n",
    "    train_df = df['2015-03-31':'2018-12-31'].dropna()\n",
    "    valid_df = df['2018-12-31':\"2020-03-31\"].dropna()\n",
    "    test_df = df['2020-03-31':].dropna()\n",
    "    \n",
    "    mean = train_df['Return'].mean()\n",
    "    print(mean)\n",
    "    \n",
    "    train_df = mean_divide_sig(train_df,mean)\n",
    "    valid_df = mean_divide_sig(valid_df,mean)\n",
    "    test_df = mean_divide_sig(test_df,mean)\n",
    "    \n",
    "    \n",
    "    X_train = train_df[factor_list].to_numpy()\n",
    "    X_valid = valid_df[factor_list].to_numpy()\n",
    "    X_test = test_df[factor_list].to_numpy()\n",
    "\n",
    "    rtn_train = train_df['Return'].to_numpy()\n",
    "    rtn_valid = valid_df['Return'].to_numpy()\n",
    "    rtn_test = test_df['Return'].to_numpy()\n",
    "    \n",
    "    Y_train = train_df['sig'].to_numpy()\n",
    "    Y_valid = valid_df['sig'].to_numpy()\n",
    "    Y_test = test_df['sig'].to_numpy()\n",
    "    \n",
    "    return X_train, Y_train, rtn_train, X_valid, Y_valid, rtn_valid, X_test, Y_test, rtn_test\n",
    "\n",
    "for sector in sector_list:\n",
    "    rtn_list=quarterly_index_rtn[sector].to_list()\n",
    "    df =get_sector_exposure(sector,factor_list)\n",
    "    df['Return']=quarterly_index_rtn[sector].to_list()\n",
    "    X_train, Y_train, rtn_train, X_valid, Y_valid, rtn_valid, X_test, Y_test, rtn_test = split_dataset(df,factor_list)\n",
    "\n",
    "    if sector == sector_list[0]:\n",
    "        X_train_total = X_train\n",
    "        Y_train_total = Y_train\n",
    "        rtn_train_total = rtn_train\n",
    "        X_valid_total = X_valid\n",
    "        Y_valid_total = Y_valid\n",
    "        rtn_valid_total = rtn_valid\n",
    "        X_test_total = X_test\n",
    "        Y_test_total = Y_test\n",
    "        rtn_test_total = rtn_test\n",
    "    else:\n",
    "        X_train_total = np.vstack((X_train_total, X_train))\n",
    "        Y_train_total = np.hstack((Y_train_total,Y_train))\n",
    "        rtn_train_total = np.hstack((rtn_train_total,rtn_train))\n",
    "        X_valid_total = np.vstack((X_valid_total,X_valid))\n",
    "        Y_valid_total = np.hstack((Y_valid_total,Y_valid))\n",
    "        rtn_valid_total = np.hstack((rtn_valid_total,rtn_valid))\n",
    "        X_test_total = np.vstack((X_test_total,X_test))\n",
    "        Y_test_total = np.hstack((Y_test_total,Y_test))\n",
    "        rtn_test_total = np.hstack((rtn_test_total,rtn_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d2718021-2134-426d-8687-5f17c3b93c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 possitive samples and 68 negative samples in the training set \n"
     ]
    }
   ],
   "source": [
    "Total_up_NO = 0\n",
    "Total_down_NO = 0\n",
    "\n",
    "for num in Y_train_total:\n",
    "    if num >0:\n",
    "        Total_up_NO += 1\n",
    "    else:\n",
    "        Total_down_NO +=1\n",
    "\n",
    "print(\"There are\",Total_up_NO,'possitive samples and', Total_down_NO,'negative samples in the training set ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "30a5f67c-804a-4039-8107-3aeea2e5541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 5\n",
      "0.6166666666666667\n",
      "0.6142857142857143\n",
      "N = 6\n",
      "0.6\n",
      "0.44285714285714284\n",
      "N = 7\n",
      "0.65\n",
      "0.5428571428571428\n",
      "N = 8\n",
      "0.6\n",
      "0.4714285714285714\n",
      "N = 9\n",
      "0.6\n",
      "0.45714285714285713\n",
      "N = 10\n",
      "0.6833333333333333\n",
      "0.5\n",
      "N = 11\n",
      "0.5833333333333334\n",
      "0.5\n",
      "N = 12\n",
      "0.6166666666666667\n",
      "0.4\n",
      "N = 13\n",
      "0.65\n",
      "0.4857142857142857\n",
      "N = 14\n",
      "0.7\n",
      "0.42857142857142855\n",
      "N = 15\n",
      "0.7\n",
      "0.35714285714285715\n",
      "N = 16\n",
      "0.6\n",
      "0.4142857142857143\n",
      "N = 17\n",
      "0.6833333333333333\n",
      "0.4857142857142857\n",
      "N = 18\n",
      "0.5833333333333334\n",
      "0.4714285714285714\n",
      "N = 19\n",
      "0.6666666666666666\n",
      "0.4714285714285714\n"
     ]
    }
   ],
   "source": [
    "for n in range(5,20):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,max_iter=1000,hidden_layer_sizes=(n,n), random_state=1)\n",
    "    clf.fit(X_train_total, Y_train_total)\n",
    "    print('N =',n)\n",
    "    print(clf.score(X_valid_total,Y_valid_total))\n",
    "    print(clf.score(X_test_total,Y_test_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f0b6294b-52fd-441e-839a-934dbe1dcc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 possitive samples and 19 negative samples in the test set \n",
      "There are 25 possitive samples and 45 negative samples in the test prediction.\n",
      "On Test Set\n",
      "There are  19 correct up prediction\n",
      "There are  13 correct down prediction\n",
      "The Correct Rate on possitive prediction is 0.76\n",
      "The Correct Rate on negative prediction is 0.28888888888888886\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,max_iter=1000,hidden_layer_sizes=(5,5), random_state=1)\n",
    "clf.fit(X_train_total, Y_train_total)\n",
    "test_up_NO = 0\n",
    "test_down_NO = 0\n",
    "for num in Y_test_total:\n",
    "    if num >0:\n",
    "        test_up_NO += 1\n",
    "    else:\n",
    "        test_down_NO +=1\n",
    "\n",
    "print(\"There are\",test_up_NO,'possitive samples and', test_down_NO,'negative samples in the test set ')\n",
    "\n",
    "test_pred_up_NO = 0\n",
    "test_pred_down_NO = 0\n",
    "\n",
    "for num in test_y_pred:\n",
    "    if num >0:\n",
    "\n",
    "        test_pred_up_NO += 1\n",
    "    else:\n",
    "        test_pred_down_NO +=1\n",
    "\n",
    "print(\"There are\",test_pred_up_NO,'possitive samples and', test_pred_down_NO,'negative samples in the test prediction.')\n",
    "\n",
    "total_up_correct = 0\n",
    "total_down_correct = 0\n",
    "\n",
    "for i in range(len(Y_test_total)):\n",
    "    if test_y_pred[i] ==1:\n",
    "        if test_y_pred[i] == Y_test_total[i]:\n",
    "            total_up_correct += 1\n",
    "    if test_y_pred[i] ==0:\n",
    "        if test_y_pred[i] == Y_test_total[i]:\n",
    "            total_down_correct +=1\n",
    "\n",
    "up_correct_rate = total_up_correct/test_pred_up_NO  \n",
    "down_correct_rate = total_down_correct/test_pred_down_NO\n",
    "print('On Test Set')\n",
    "print('There are ',total_up_correct,'correct up prediction')\n",
    "print('There are ',total_down_correct,'correct down prediction')\n",
    "print('The Correct Rate on possitive prediction is',up_correct_rate)\n",
    "print('The Correct Rate on negative prediction is',down_correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "67f7b45a-520f-4602-9bef-1a50c4ad913e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
      "[0.2867502209005208, 0.2926888786144628, 0.10132736494801287, 0.25279798333235237, 0.13924646967671972, 0.04509718498378046, -0.03941821231547116, 0.16404873718512358, 0.1519333411340651, 0.10998746553849581, 0.3256926067696939, -0.0014876207067449077, 0.07317116475786256, 0.0045094420195901375, 0.03168154348069385, -0.009755796745937517, 0.1306031773313232, 0.07553897458142078, 0.027439336353658028, 0.10777030510832475, 0.30101246890126054, 0.11654806032126164, 0.11521686550999011, 0.0173614876822199, 0.11300434752118926, 0.0113125166608532, 0.1644999333680175, 0.1351986902471083, 0.013958775543224888, -0.002089231018659654, 0.018419287726202827, 0.05192359332781771, 0.01940013902397264, 0.12328696051688204, 0.011830479722252818, 0.08380871703042203, 0.0024512187409628794, 0.16778742249204748]\n",
      "The Annually cumulative return on test set is 2.3474341315951266\n",
      "The sharpe ratio is 2.0843065790316375\n"
     ]
    }
   ],
   "source": [
    "#only trade on positive prediction\n",
    "win_num=0\n",
    "total_rtn=0\n",
    "rtn_list=[]\n",
    "trading_len = len(rtn_test_total)/(11*4) # we have eleven sector with quarterly frequency, yields to 11*4 samples per year \n",
    "print(test_y_pred)\n",
    "for i in range(0,len(test_y_pred)):\n",
    "    if test_y_pred[i] > 0:\n",
    "        rtn = test_y_pred[i]*rtn_test_total[i]\n",
    "        rtn_list.append(rtn)\n",
    "        total_rtn += rtn\n",
    "print(rtn_list)\n",
    "sharpe_ratio=(np.mean(rtn_list)*4)/(np.std(rtn_list)*4**(1/2))\n",
    "\n",
    "print('The Annually cumulative return on test set is '+ str(total_rtn/trading_len))\n",
    "print('The sharpe ratio is',sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8f57d-827f-4c47-9705-794a24901121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
